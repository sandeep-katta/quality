package com.ubs.qualityTests.accountingRuleBig

import com.ubs.quality._
import com.ubs.qualityTests.{RowTools, TestUtils}
import org.apache.spark.sql.execution.QueryExecution
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types.{DataType, IntegerType}
import org.apache.spark.sql.{DataFrame, Encoders, SparkSession}
import org.junit.Test
import org.scalatest.FunSuite

case class ComplexPosting(Rule_No: String,ACCOUNTING_PROFIT_CENTER: String,BUSINESS_DATE: String,BUSINESS_OBJECTIVE_IDENTIFIER: String,CLIENT_ADVISER_IDENTIFIER: String,CLIENT_ASSET_LIABILITY_FLOW_CLASS: String,CLIENT_ASSET_TYPE: String,CLIENT_LIABILITY_TYPE: String,COMPLEX_CONTRACT_IDENTIFIER: String,COMPLEX_CONTRACT_SOURCE_SYSTEM_IDENTIFIER: String,COUNTRY_OF_INCORPORATION: String,CREATED_TIMESTAMP: String,DEBIT_OR_CREDIT_IDENTIFIER: String,DELIVERING_APPLICATION_SYSTEM_IDENTIFIER: String,DEPENDENT_CONTRACT_IDENTIFIER: String,DEPENDENT_CONTRACT_SOURCE_SYSTEM_IDENTIFIER: String,DOMESTIC_AMOUNT: String,DOMESTIC_CURRENCY_CODE: String,ELEMENTARY_CONTRACT_IDENTIFIER: String,ELEMENTARY_CONTRACT_SOURCE_SYSTEM_IDENTIFIER: String,FISCAL_YEAR_PERIOD: String,GAAP_ADJUSTMENT_CODE: String,GAAP_CODE: String,GENERAL_LEDGER_ACCOUNT_IDENTIFIER: String,GENERAL_LEDGER_GROUP_ACCOUNT_IDENTIFIER: String,GROUP_AMOUNT_1: String,GROUP_AMOUNT_2: String,GROUP_CURRENCY_CODE_1: String,GROUP_CURRENCY_CODE_2: String,INSTRUMENT_IDENTIFIER: String,INSTRUMENT_SOURCE_SYSTEM_IDENTIFIER: String,LEDGER_IDENTIFIER: String,LOCAL_AMOUNT: String,LOCAL_CURRENCY_CODE: String,MOVEMENT_TYPE_CODE: String,PARTNER_RELATIONSHIP_IDENTIFIER: String,PARTNER_RELATIONSHIP_SOURCE_SYSTEM_IDENTIFIER: String,POSITION_IDENTIFIER: String,POSITION_SOURCE_SYSTEM_IDENTIFIER: String,POSTING_DATE: String,POSTING_GENERATION_RULE_NAME: String,POSTING_TEXT: String,POSTING_TYPE_INDICATOR: String,REGULATORY_PRODUCT_TYPE_CODE: String,REPORTING_AMOUNT_TYPE_CODE: String,RISK_HOLDING_LEGAL_ENTITY_IDENTIFIER: String,SEQUENCE_NUMBER: String,SUB_BOOK_IDENTIFIER: String,SUB_CONSOLIDATION_AMOUNT_1: String,SUB_CONSOLIDATION_AMOUNT_2: String,SUB_CONSOLIDATION_CURRENCY_CODE_1: String,SUB_CONSOLIDATION_CURRENCY_CODE_2: String,SUB_PRODUCT_TYPE_SUFFIX: String,TAX_CODE: String,TRADING_BOOK_IDENTIFIER: String,TRADING_PARTNER: String,TRANSACTION_AMOUNT: String,TRANSACTION_CURRENCY_CODE: String,TRANSACTION_IDENTIFIER: String,TRANSACTION_LINK_IDENTIFIER: String,TRANSACTION_LINK_SOURCE: String,TRANSACTION_ORIGINATING_APPLICATION_SYSTEM_IDENTIFIER: String,TRANSACTION_SOURCE_SYSTEM_IDENTIFIER: String,TRANSLATION_DATE: String)

case class ComplexPosting2(Rule_No: String,ACCOUNTING_PROFIT_CENTER: String, BUSINESS_DATE: String)


case class ASR(test_col1: String,	test_col2: String,	test_col3: String,	test_col4: String,	test_col5: String,	test_col6: String,	test_col7: String,	test_col8: String,	test_col9: String,	test_col10: String,	test_col11: String,	test_col12: String,	test_col13: String,	test_col14: String,	test_col15: String,	test_col16: String,	test_col17: String,	test_col18: String,	test_col19: String,	test_col20: String,	test_col21: String,	test_col22: String,	test_col23: String,	test_col24: String,	test_col25: String,	test_col26: String,	test_col27: String,	test_col28: String,	test_col29: String,	test_col30: String,	test_col31: String,	test_col32: String,	test_col33: String,	test_col34: String,	test_col35: String,	test_col36: String,	test_col37: String,	test_col38: String,	test_col39: String,	test_col40: String,	test_col41: String,	test_col42: String,	test_col43: String,	test_col44: String,	test_col45: String,	test_col46: String,	test_col47: String,	test_col48: String,	test_col49: String,	test_col50: String,
               TRADE_DATE : String, BUSINESS_DATE : String, VALUE_DATE : String, SETTLEMENT_DATE : String, REGULATORY_PRODUCT_TYPE_CODE : String, SUB_PRODUCT_TYPE_SUFFIX : String, ASSET_LIABILITY_TYPE : String, PROFIT_LOSS_TYPE : String, BUSINESS_GROUP : String, UBS_ROLE : String, BUSINESS_OBJECTIVE_IDENTIFIER : String, POSITION_TYPE : String, ITEM_TYPE_CODE : String, CLIENT_ADVISOR_IDENTIFIER : String, DEPENDENT_CONTRACT_IDENTIFIER : String, DEPENDENT_CONTRACT_SOURCE_SYSTEM_IDENTIFIER : String, ELEMENTARY_CONTRACT_IDENTIFIER : String, ELEMENTARY_CONTRACT_SOURCE_SYSTEM_IDENTIFIER : String, COMPLEX_CONTRACT_IDENTIFIER : String, COMPLEX_CONTRACT_SOURCE_SYSTEM_IDENTIFIER : String, ACCOUNTING_TREATMENT : String, MULTI_GAAP_ACCOUNTING_CLASSIFICATION : String, PROFIT_CENTER : String, RISK_HOLDING_LEGAL_ENTITY_IDENTIFIER : String, COUNTRY_OF_INCORPORATION : String, LEDGER_IDENTIFIER : String, COUNTERPARTY_TYPE : String, DUAL_BOOKED_TYPE : String, OWN_ISSUANCE_FLAG : String, FUNDED_FLAG : String, NON_PERFORMING_ASSETS : String, AMOUNT_DIRECTION : String, BOOKING_EVENT : String, EXPOSURE_CURRENCY : String, LOCAL_CURRENCY : String, SETTLEMENT_CURRENCY_CODE : String, CONTRACT_RELATED_CURRENCY_CODE : String, NOTIONAL_PAYABLE_CURRENCY_CODE : String, NOTIONAL_RECEIVABLE_CURRENCY_CODE : String, TRADING_VENUE : String, AVI_VS_IVI : String, DATA_GRAIN : String, ACCOUNTING_PROCESSING_TYPE : String, TRANSACTION_IDENTIFIER : String, TRANSACTION_ORIGINATING_APPLICATION_SYSTEM_IDENTIFIER : String, POSITION_IDENTIFIER : String, POSITION_ID_SOURCE_SYSTEM_IDENTIFIER : String, STRUCTURE_TRADE_GROUP_IDENTIFIER : String, STRUCTURE_TRADE_GROUP_IDENTIFIER_SOURCE : String, DELIVERING_APPLICATION_IDENTIFIER : String, INSTRUMENT_IDENTIFIER : String, INSTRUMENT_IDENTIFIER_SOURCE_SYSTEM_IDENTIFIER : String, PARTNER_RELATIONSHIP_IDENTIFIER : String, PARTNER_RELATIONSHIP_SOURCE_SYSTEM_IDENTIFIER : String, AMOUNT_TYPE_DOMAIN : String, AMOUNT_TYPE : String, TRANSACTION_CURRENCY_AMOUNT : String, LOCAL_CURRENCY_AMOUNT : String, FACILITY_IDENTIFIER : String, FACILITY_ID_SOURCE_SYSTEM_IDENTIFER : String, CLIENT_LIABILITY_TYPE : String, CLIENT_ASSET_TYPE : String, CLIENT_ASSET_LIABILITY_FLOW_CLASS : String, BOOK_IDENTIFIER : String, BUSINESS_TYPE_IDENTIFIER : String, PARTNER_ACCOUNTING_CATEGORY_CODE : String, REPORTING_AMOUNT_TYPE_CODE : String, POSTING_TEXT : String, CONTRACT_CATEGORY_CODE : String, TRADING_PARTNER : String)

class RuleEngineTestBig extends FunSuite with RowTools with TestUtils {

  @Test
  def testAccountingRules(): Unit = {

    // Attempt to load some rules ...
    //    val df = toDS(rules)

    import sparkSession.implicits._

    val spark = sparkSession
      /*.builder
      .appName("SparkSQLExampleApp")
      .config("spark.sql.debug.maxToStringFields", 3L)
      .getOrCreate() */

    val ruleSchema = Encoders.product[RuleRow].schema

    val dfRuleSuitesRaw = spark.read.option("header", value = true).option("escape", "\"").///schema(ruleSchema).
      csv("src/test/scala/com/ubs/qualityTests/accountingRuleBig/accounting_rules_test2.csv")

    val uniqueOutputExpressions = dfRuleSuitesRaw.selectExpr("ruleEngineExpr").distinct.
      selectExpr("ruleEngineExpr","monotonically_increasing_id() as mid").
      selectExpr("ruleEngineExpr", "unpack(mid) as id", "-1 as gruleSuiteId", "-1 as gruleSuiteVersion").
      selectExpr( "*", "id.id as truleEngineId", "id.version as truleEngineVersion").drop("id")

    val dfRuleSuites = spark.read.option("header", value = true).option("escape", "\"").schema(ruleSchema).
      csv("src/test/scala/com/ubs/qualityTests/accountingRuleBig/accounting_rules_test2.csv")
      //.selectExpr("*", "ruleId as truleEngineId", "ruleVersion as truleEngineVersion")
      //.selectExpr("*", "ruleEngineExpr as tRuleEngineExpr")
      .join(uniqueOutputExpressions, uniqueOutputExpressions.col("ruleEngineExpr").equalTo(col("ruleEngineExpr")))

    val outputExpressions = readOutputExpressionsFromDF(uniqueOutputExpressions,
      col("ruleEngineExpr"),
      col("truleEngineId").cast(IntegerType),
      col("truleEngineVersion").cast(IntegerType),
      col("gruleSuiteId").cast(IntegerType),
      col("gruleSuiteVersion").cast(IntegerType)
    )

    val ruleSuiteWithoutLambdas = readRulesFromDF(dfRuleSuites,
      col("ruleSuiteId"),
      col("ruleSuiteVersion"),
      col("ruleSetId"),
      col("ruleSetVersion"),
      col("ruleId"),
      col("ruleVersion"),
      col("ruleExpr"),
      col("ruleEngineSalience"),
      col("truleEngineId"),
      col("truleEngineVersion")
    )

    // Read in the lambdas
    val lambdaSchema = Encoders.product[LambdaFunctionRow].schema

    val dfLambdaFunctions = spark.read.option("header", value = true).option("escape", "\"").schema(lambdaSchema).csv(path = "src/test/scala/com/ubs/qualityTests/accountingRuleBig/accounting_lambda_function_test2.csv")

    val lambdas = readLambdasFromDF(dfLambdaFunctions,
      col("name"),
      col("ruleExpr"),
      col("functionId"),
      col("functionVersion"),
      col("ruleSuiteId"),
      col("ruleSuiteVersion")
    )

    val accountingRuleSuiteRaw = integrateLambdas(ruleSuiteWithoutLambdas, lambdas)
    val (accountingRuleSuite, missing) = integrateOutputExpressions(accountingRuleSuiteRaw, outputExpressions, Some(Id(-1,-1)))


    // Sort out a new lambda function

    val rules = accountingRuleSuite(Id(1, 1))

    rules.ruleSets foreach (x => x.rules.find(_.id.id==0).foreach(println))

    //    DataType.fromDDL("ARRAY<STRUCT<`transfer_type`: STRING, `account`: STRING>>"), debugMode = false)

    // Load the test data

    val asrSchema = Encoders.product[ASR].schema

    val testDataDF = spark.read.option("header", value = true)
      .option("escape", "\"")
      .schema(asrSchema)
      .csv(path = "src/test/scala/com/ubs/qualityTests/accountingRuleBig/accountingsourcerecord.csv").repartition(8)

    val rer = ruleEngineRunner(rules,
      DataType.fromDDL("ARRAY<STRUCT<`Rule_No`: String,`ACCOUNTING_PROFIT_CENTER`: String,`BUSINESS_DATE`: String,`BUSINESS_OBJECTIVE_IDENTIFIER`: String,`CLIENT_ADVISER_IDENTIFIER`: String,`CLIENT_ASSET_LIABILITY_FLOW_CLASS`: String,`CLIENT_ASSET_TYPE`: String,`CLIENT_LIABILITY_TYPE`: String,`COMPLEX_CONTRACT_IDENTIFIER`: String,`COMPLEX_CONTRACT_SOURCE_SYSTEM_IDENTIFIER`: String,`COUNTRY_OF_INCORPORATION`: String,`CREATED_TIMESTAMP`: String,`DEBIT_OR_CREDIT_IDENTIFIER`: String,`DELIVERING_APPLICATION_SYSTEM_IDENTIFIER`: String,`DEPENDENT_CONTRACT_IDENTIFIER`: String,`DEPENDENT_CONTRACT_SOURCE_SYSTEM_IDENTIFIER`: String,`DOMESTIC_AMOUNT`: String,`DOMESTIC_CURRENCY_CODE`: String,`ELEMENTARY_CONTRACT_IDENTIFIER`: String,`ELEMENTARY_CONTRACT_SOURCE_SYSTEM_IDENTIFIER`: String,`FISCAL_YEAR_PERIOD`: String,`GAAP_ADJUSTMENT_CODE`: String,`GAAP_CODE`: String,`GENERAL_LEDGER_ACCOUNT_IDENTIFIER`: String,`GENERAL_LEDGER_GROUP_ACCOUNT_IDENTIFIER`: String,`GROUP_AMOUNT_1`: String,`GROUP_AMOUNT_2`: String,`GROUP_CURRENCY_CODE_1`: String,`GROUP_CURRENCY_CODE_2`: String,`INSTRUMENT_IDENTIFIER`: String,`INSTRUMENT_SOURCE_SYSTEM_IDENTIFIER`: String,`LEDGER_IDENTIFIER`: String,`LOCAL_AMOUNT`: String,`LOCAL_CURRENCY_CODE`: String,`MOVEMENT_TYPE_CODE`: String,`PARTNER_RELATIONSHIP_IDENTIFIER`: String,`PARTNER_RELATIONSHIP_SOURCE_SYSTEM_IDENTIFIER`: String,`POSITION_IDENTIFIER`: String,`POSITION_SOURCE_SYSTEM_IDENTIFIER`: String,`POSTING_DATE`: String,`POSTING_GENERATION_RULE_NAME`: String,`POSTING_TEXT`: String,`POSTING_TYPE_INDICATOR`: String,`REGULATORY_PRODUCT_TYPE_CODE`: String,`REPORTING_AMOUNT_TYPE_CODE`: String,`RISK_HOLDING_LEGAL_ENTITY_IDENTIFIER`: String,`SEQUENCE_NUMBER`: String,`SUB_BOOK_IDENTIFIER`: String,`SUB_CONSOLIDATION_AMOUNT_1`: String,`SUB_CONSOLIDATION_AMOUNT_2`: String,`SUB_CONSOLIDATION_CURRENCY_CODE_1`: String,`SUB_CONSOLIDATION_CURRENCY_CODE_2`: String,`SUB_PRODUCT_TYPE_SUFFIX`: String,`TAX_CODE`: String,`TRADING_BOOK_IDENTIFIER`: String,`TRADING_PARTNER`: String,`TRANSACTION_AMOUNT`: String,`TRANSACTION_CURRENCY_CODE`: String,`TRANSACTION_IDENTIFIER`: String,`TRANSACTION_LINK_IDENTIFIER`: String,`TRANSACTION_LINK_SOURCE`: String,`TRANSACTION_ORIGINATING_APPLICATION_SYSTEM_IDENTIFIER`: String,`TRANSACTION_SOURCE_SYSTEM_IDENTIFIER`: String,`TRANSLATION_DATE`: String>>"),
      debugMode = false, compileEvals = true, /*resolveWith = Some(testDataDF), */forceRunnerEval = false, forceTriggerEval = true) // b4ms without resolve 5m 38s )// got 6m43 spark 2 normal plans - original temp/alex_unevaluable.
    // 5m27s via compiled non resolve at 1k, 1m44 withResolve at 1k. withResolve compiled at at 1m 5m39s, uncompiled at 3m46 - i.e. Alex time, so faster compiled?

    // spark 3 local file resolvewith and compile 5m 14s, 4m 55s second run, without compilation -

    /*
    val outdf = testDataDF.select(expr("*"), rer.as("together")).selectExpr("*", "together.result")
/*
    val f = java.io.File.createTempFile("pre","post")
    f.delete
    toutdf.write.parquet(f.getAbsolutePath)
    val outdf = sparkSession.read.parquet(f.getAbsolutePath)
*/
    outdf.show()
*/
    val outdf = // testDataDF.filter("test_col1 is not null")
      testDataDF.select(expr("*"), rer.as("together")).
       // drop("together").//selectExpr("*","test_col3 as together")
       // selectExpr("*","named_struct('res_col3', if(length(test_col3) > 3, 234, length(test_col3) - 3) , 'res_col11', if(length(test_col11) < 20, 8493*length(test_col11), 20), 'res_col22', if(test_col22 < test_col8, length(profit_center), RISK_HOLDING_LEGAL_ENTITY_IDENTIFIER), 'result', if( length(test_col33) = 305, BUSINESS_GROUP, UBS_ROLE)) as together").
        selectExpr("*", "together.result")

    //doShow(outdf)
    //doCount(outdf)
    doWrite(outdf)
  /*  val res = outdf.select("result").as[Seq[ComplexPosting]].toLocalIterator()


    println(res.next())
*/
    // assert(res(0) == Seq(Posting("from", "1234"), Posting("to","other_account1")))

  }

  def doShow(df: DataFrame) = debugTime("show") {
    df.show()
  }

  def doCount(df: DataFrame) = debugTime("count") {
    println(s"${df.count()} - count")
  }

  def doWrite(df: DataFrame) = debugTime("write") {
    //val f = java.io.File.createTempFile("pre","post")
    //f.delete
    //println(s"filepath is ${f.getAbsolutePath}")
    //df.write.option("header",true).parquet(f.getAbsolutePath)
    df.write.option("header",true).mode("overwrite").parquet("./target/accResBig")
  }



}

